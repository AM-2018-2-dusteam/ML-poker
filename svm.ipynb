#Aluno: Geovanne Santos Saraiva 150035756

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.utils import column_or_1d
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
import seaborn as sn
import timeit
from format import format_poker_data
from sklearn import svm
#start to count how long i fit my model
inicio = time.time()

#train_data and test_data receive the files below
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

#X_train receive the features and y_train receive the label(is the last column, the type of the poker hand)
X_train, y_train = np.split(train_data,[-1],axis=1)

test_data = test_data.dropna()

#this make the samething, but with other file, the test_data
X_test, y_test = np.split(test_data,[-1],axis=1)

#this make easier to the machine understand this column, if were all true is one if is not is false
#we use this to verify if the poker hand have all the cards with the same type
X_train = pd.get_dummies(X_train,columns=['suit_1','suit_2','suit_3','suit_4','suit_5'])
X_test = pd.get_dummies(X_test,columns=['suit_1','suit_2','suit_3','suit_4','suit_5'])

rank_train, suit_train = np.split(X_train,[5],axis=1)
rank_test, suit_test = np.split(X_test,[5],axis=1)

rank_train.values.sort()
rank_test.values.sort()

#support vector machine method
#Kernel=rbf is largely useful without non-linear separation problem.
#In gamma = 10 the kernel propagation is less pronounced. Decision limit begins
#to be highly affected by individual data points, so to predict it gets worse, so I used the smaller gamma.

r = SVC(kernel='rbf', random_state=0, gamma=.01, C=1)

r = r.fit(rank_train, y_train)

pred = r.predict(rank_test)

fim = time.time()

#this metric shows how our prediction hits each label
scores = cross_val_score(r, X=rank_test, y=y_test, cv=2)

soma=0
for c in scores:
        soma = soma+c

media = soma/(len(scores))

print('#######[Decision Tree]#######')
print("Assertividade dados de treino: ", r.score(rank_train, y_train))
print("Assertividade dados de teste: ", r.score(rank_test, y_test))
print("Assertividade cross validation dados de teste", media)

tempototal = fim - inicio
print("Tempo total de execução: ",tempototal)

#the results can be checked in this link(in the svm part):https://docs.google.com/presentation/d/1zFS4cTf9xwvcVPiCOA-sV_RFx_UeoNX2dTthHkY9Am4/edit#slide=id.g3f7fc2ccb4_7_75
